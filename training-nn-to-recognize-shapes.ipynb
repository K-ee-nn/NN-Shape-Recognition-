{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Neural Network to regconise circles, squares, triangles.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np   # linear algebra \nimport pandas as pd  # data processing\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-22T14:23:45.180441Z","iopub.execute_input":"2021-10-22T14:23:45.180751Z","iopub.status.idle":"2021-10-22T14:23:45.493189Z","shell.execute_reply.started":"2021-10-22T14:23:45.180670Z","shell.execute_reply":"2021-10-22T14:23:45.492508Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir('../input/') # Changing the directory","metadata":{"execution":{"iopub.status.busy":"2021-10-22T14:23:57.730806Z","iopub.execute_input":"2021-10-22T14:23:57.731084Z","iopub.status.idle":"2021-10-22T14:23:57.734749Z","shell.execute_reply.started":"2021-10-22T14:23:57.731055Z","shell.execute_reply":"2021-10-22T14:23:57.733972Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf=pd.DataFrame()\npath=[]\nlabel=[]\ncode=[]\nlst=[\"circles\",\"squares\",\"triangles\"]\nfor i in lst:\n  super=os.listdir('basicshapes/shapes/'+i)\n  for j in super:\n    path.append(j)\n    label.append(i)\n    if i==\"circles\":\n      code.append(0)\n    elif i==\"squares\":\n      code.append(1)\n    else:\n      code.append(2)\ndf[\"label\"]=label\ndf[\"path\"]=path\ndf[\"code\"]=code\n\nimport cv2\nfrom tqdm import tqdm\nimport numpy as np\nimport random\nimport tensorflow as tf\n\nimage=[]\nlst=[\"circles\",\"squares\",\"triangles\"]\nfor i in tqdm(lst):\n  b='basicshapes/shapes/'+i\n  a=os.listdir('basicshapes/shapes/'+i)\n  for j in a:\n    image.append(cv2.imread(b+'/'+j))\ndf[\"image\"]=image\n\nfor index,row in df.iterrows():\n  print(np.shape(row.image))\n\ndom=[]\nfor i in range(0,240):\n  dom.append(0)\nfor i in range(240,270):\n  dom.append(1)\nfor i in range(270,300):\n  dom.append(2)\nrandom.shuffle(dom)\ndf[\"subset\"]=dom\n\ndf\n\ndf.groupby(\"label\")[\"subset\"].value_counts()\n\nlst=[\"circles\",\"squares\",\"triangles\"]\nnew_df=pd.DataFrame()\nfor i in lst:\n  new_df=df[df.label==i].sample(10)\n  for j in new_df[\"image\"]:\n    print(j)\n\ndef generate(df,batch):\n  num=batch/3\n  while 1:\n    image=[]\n    label=[]\n    for i in lst:\n      new_df=df[df.label==i].sample(batch//3,replace=True)\n      for j in new_df[\"image\"]:\n        image.append(j)\n      for j in new_df[\"code\"]:\n        label.append(j)\n    image=np.array(image)\n    label=np.array(label)\n    label=tf.keras.utils.to_categorical(label)\n    yield image,label\n\n\nx,y=next(generate(df,30))\nprint(x.shape)\n\nprint(len(df[(df.subset==1) & (df.label==\"triangles\")]))\n\nmodel = tf.keras.Sequential(\n    [\n\n        tf.keras.Input(shape=(28,28,3)),\n        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(3, activation=\"softmax\"),\n    ]\n)\n\nmodel.summary()\n\nbatch_size = 30\nepochs = 5\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\nmodel.fit(generate(df[df.subset==0],batch_size), batch_size=batch_size, epochs=epochs,steps_per_epoch=100,validation_steps=100,validation_data=generate(df[df.subset==1],batch_size))\n\nscore = model.evaluate(generate(df[df.subset==2],batch_size), verbose=0,steps=100)\nprint(\"Test loss:\", score[0])\nprint(\"Test accuracy:\", score[1])","metadata":{"execution":{"iopub.status.busy":"2021-10-22T14:24:00.395711Z","iopub.execute_input":"2021-10-22T14:24:00.396166Z","iopub.status.idle":"2021-10-22T14:24:21.772360Z","shell.execute_reply.started":"2021-10-22T14:24:00.396131Z","shell.execute_reply":"2021-10-22T14:24:21.771524Z"},"trusted":true},"execution_count":3,"outputs":[]}]}